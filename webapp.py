import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import matplotlib.pyplot as plt
import tempfile
import os
from moviepy.editor import ImageSequenceClip

# -------------------------------------------------------------------
# 1. ìµœì¢… ë¶„ì„ ì—”ì§„ (ëª¨ë“  ê´€ì ˆ ë–¨ë¦¼ ë³´ì • ê¸°ëŠ¥ íƒ‘ì¬)
# -------------------------------------------------------------------
def analyze_swing(video_path, progress_bar):
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.7)
    mp_drawing = mp.solutions.drawing_utils

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ ì „ì²´ í”„ë ˆì„ ìˆ˜

    # --- ìŠ¤ë¬´ë”© ë° ë¶„ì„ ë³€ìˆ˜ ì„¤ì • ---
    output_frames = []
    window_size = 7  # ìŠ¤ë¬´ë”© ì°½ í¬ê¸°
    landmark_buffers = {i: [] for i in range(33)} # 33ê°œ ëª¨ë“  ê´€ì ˆì„ ìœ„í•œ ë²„í¼

    swing_plane_line = None
    min_y_coord = 9999
    top_position_coords = None
    address_wrist_y = 0
    backswing_height = 0
    impact_hand_y = 0
    top_detected = False
    right_hand_path = []

    if not cap.isOpened():
        return None, None, None

    display_height = 720
    display_width = int(display_height * 9 / 16)
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30.0

    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        progress_bar.progress(frame_count / total_frames)

        resized_frame = cv2.resize(frame, (display_width, display_height))
        image_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
        image_rgb.flags.writeable = False
        results = pose.process(image_rgb)
        image_rgb.flags.writeable = True

        if results.pose_landmarks:
            # ëª¨ë“  ê´€ì ˆì— ì´ë™ í‰ê·  í•„í„° ì ìš©
            for i, landmark in enumerate(results.pose_landmarks.landmark):
                buffer = landmark_buffers[i]
                buffer.append([landmark.x, landmark.y, landmark.z, landmark.visibility])
                if len(buffer) > window_size:
                    buffer.pop(0)

                smoothed_point = np.mean(buffer, axis=0)
                # ê¸°ì¡´ landmark ê°’ì„ ìŠ¤ë¬´ë”©ëœ ê°’ìœ¼ë¡œ ë®ì–´ì“°ê¸°
                landmark.x, landmark.y, landmark.z, landmark.visibility = smoothed_point

            # ì´ì œ 'results.pose_landmarks' ìì²´ê°€ ë³´ì •ëœ ê°’ì„ ê°€ì§
            landmarks = results.pose_landmarks.landmark
            right_wrist_landmark = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]

            if right_wrist_landmark.visibility > 0.7:
                if swing_plane_line is None:
                    # ì–´ë“œë ˆìŠ¤ ìì„¸ ì„¤ì •
                    shoulder_x = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x + landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2
                    shoulder_y = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y + landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2
                    wrist_x = (landmarks[mp_pose.PoseLandmark.LEFT_WRIST].x + right_wrist_landmark.x) / 2
                    wrist_y = (landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y + right_wrist_landmark.y) / 2
                    p1 = (int(wrist_x * display_width), int(wrist_y * display_height))
                    p2 = (int(shoulder_x * display_width), int(shoulder_y * display_height))
                    swing_plane_line = (p1, p2)
                    address_wrist_y = p1[1]
                
                right_wrist_coord = (int(right_wrist_landmark.x * display_width), int(right_wrist_landmark.y * display_height))
                right_hand_path.append(right_wrist_coord)

                # ë°±ìŠ¤ìœ™ íƒ‘ ìœ„ì¹˜ ê³„ì‚°
                if right_wrist_coord[1] < min_y_coord:
                    min_y_coord = right_wrist_coord[1]
                    top_position_coords = right_wrist_coord
                    top_detected = True
                    if address_wrist_y > 0:
                        backswing_height = address_wrist_y - min_y_coord
                
                # ì„íŒ©íŠ¸ ìˆœê°„ ì† ë†’ì´ ê³„ì‚°
                if top_detected and impact_hand_y == 0 and right_wrist_coord[1] >= address_wrist_y * 0.95:
                    impact_hand_y = right_wrist_coord[1]

        # --- í™”ë©´ì— ê·¸ë¦¬ê¸° ---
        text = f"Backswing Height: {backswing_height} px"
        cv2.putText(resized_frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)
        if swing_plane_line:
            cv2.line(resized_frame, swing_plane_line[0], swing_plane_line[1], color=(255, 0, 0), thickness=2)
        if len(right_hand_path) > 1:
            cv2.polylines(resized_frame, [np.array(right_hand_path)], isClosed=False, color=(0, 255, 0), thickness=3)
        if top_position_coords:
            cv2.circle(resized_frame, top_position_coords, 10, (0, 255, 255), 3)
        if results.pose_landmarks:
            mp_drawing.draw_landmarks(image=resized_frame, landmark_list=results.pose_landmarks, connections=mp_pose.POSE_CONNECTIONS)

        output_frames.append(cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB))

    cap.release()

    # --- ë¶„ì„ ê²°ê³¼ ë° ê·¸ë˜í”„ ìƒì„± ---
    analysis_results = {
        "max_height": backswing_height,
        "impact_height_vs_address": impact_hand_y - address_wrist_y if impact_hand_y > 0 else 0
    }

    fig = None
    if right_hand_path:
        hand_heights = [p[1] for p in right_hand_path]
        hand_heights_inverted = [display_height - h for h in hand_heights]
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(hand_heights_inverted, color='green', label='Hand Height')
        ax.set_title('Hand Height Over Time')
        ax.set_xlabel('Frame Number')
        ax.set_ylabel('Hand Height (pixels from bottom)')
        ax.legend()
        ax.grid(True)

    output_video_path = None
    if output_frames:
        output_video_path = os.path.join(tempfile.gettempdir(), 'swing_output_final.mp4')
        clip = ImageSequenceClip(output_frames, fps=fps)
        clip.write_videofile(output_video_path, codec='libx264', logger=None)

    return output_video_path, fig, analysis_results

# -------------------------------------------------------------------
# 2. ìŠ¤íŠ¸ë¦¼ë¦¿(Streamlit) ì›¹ì‚¬ì´íŠ¸ UI ì½”ë“œ
# -------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="AI ê³¨í”„ ìŠ¤ìœ™ ë¶„ì„")
st.title("ğŸŒï¸ AI ê³¨í”„ ìŠ¤ìœ™ ìë™ ë¶„ì„ ë¦¬í¬íŠ¸")
st.info("ê°œì„ ëœ AI ì—”ì§„ì´ íƒ‘ì¬ë˜ì–´ ëª¨ë“  ê´€ì ˆì˜ ë–¨ë¦¼ì„ ë³´ì •í•˜ê³  ë” ì •í™•í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.")

uploaded_file = st.file_uploader("MP4 í˜•ì‹ì˜ ìŠ¤ìœ™ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="mp4")

if uploaded_file is not None:
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ê²½ë¡œ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
        tfile.write(uploaded_file.read())
        temp_video_path = tfile.name

    st.header("âœ… ì—…ë¡œë“œëœ ì›ë³¸ ì˜ìƒ")
    st.video(temp_video_path)

    if st.button("ë¶„ì„ ì‹œì‘!"):
        # ì§„í–‰ë¥  í‘œì‹œì¤„ ìƒì„±
        progress_bar = st.progress(0, text="ìŠ¤ìœ™ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.")
        
        # ê°œì„ ëœ ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œ
        result_video_path, result_graph, insights = analyze_swing(temp_video_path, progress_bar)
        
        # ë¶„ì„ ì™„ë£Œ í›„ ì§„í–‰ë¥  100%ë¡œ ì±„ìš°ê³  ë©”ì‹œì§€ í‘œì‹œ
        progress_bar.progress(1.0, text="ë¶„ì„ ì™„ë£Œ!")

        if result_video_path:
            st.success("ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            col1, col2 = st.columns(2)
            with col1:
                st.header("ë¶„ì„ ê²°ê³¼ ì˜ìƒ")
                with open(result_video_path, 'rb') as video_file:
                    video_bytes = video_file.read()
                st.video(video_bytes)

            with col2:
                st.header("ì† ë†’ì´ ê·¸ë˜í”„")
                st.pyplot(result_graph)

            st.header("â€âš•ï¸ ìë™ ìŠ¤ìœ™ ì§„ë‹¨ ë¦¬í¬íŠ¸")
            st.metric("ìµœëŒ€ ë°±ìŠ¤ìœ™ ë†’ì´ (ì–´ë“œë ˆìŠ¤ ëŒ€ë¹„)", f"{insights['max_height']} px")
            impact_metric = insights['impact_height_vs_address']
            st.metric("ì„íŒ©íŠ¸ ì‹œ ì† ë†’ì´ (ì–´ë“œë ˆìŠ¤ ëŒ€ë¹„)", f"{impact_metric} px")

            if impact_metric <= 10:
                st.info("âœ”ï¸ **ì„íŒ©íŠ¸ í¬ì§€ì…˜**: ì¢‹ìŠµë‹ˆë‹¤! ì–´ë“œë ˆìŠ¤ì™€ ìœ ì‚¬í•œ ì¢‹ì€ ì„íŒ©íŠ¸ ë†’ì´ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ **ê°œì„ ì **: ì„íŒ©íŠ¸ ì‹œ ì†ì´ ì–´ë“œë ˆìŠ¤ë³´ë‹¤ ë†’ê²Œ ëœ¨ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ìƒì²´ê°€ ì¼ì° ì¼ì–´ë‚˜ëŠ” 'ë°°ì¹˜ê¸°' ë™ì‘ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸í•´ ë³´ì„¸ìš”.")
        
        else:
            st.error("ì˜ìƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì˜ìƒì„ ì‹œë„í•´ ë³´ê±°ë‚˜, ì˜ìƒì´ ë„ˆë¬´ ì§§ì§€ ì•Šì€ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
